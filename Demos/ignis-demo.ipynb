{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install sounddevice scipy elevenlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import os\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents.agent_toolkits import ZapierToolkit\n",
    "from langchain.utilities.zapier import ZapierNLAWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elevenlabs import set_api_key, generate, play\n",
    "set_api_key(os.getenv(\"ELEVENLABS_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Currently using Small model for fast responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model = whisper.load_model('small.en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guilhermezago/Documents/GPT-Vectorized-Analysis/.venv/lib/python3.11/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "result = small_model.transcribe('ignition.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' Find Gennaro in my contacts list, then send him an email about AI automation.',\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 7.0,\n",
       "   'text': ' Find Gennaro in my contacts list, then send him an email about AI automation.',\n",
       "   'tokens': [50363,\n",
       "    9938,\n",
       "    402,\n",
       "    1697,\n",
       "    12022,\n",
       "    287,\n",
       "    616,\n",
       "    13961,\n",
       "    1351,\n",
       "    11,\n",
       "    788,\n",
       "    3758,\n",
       "    683,\n",
       "    281,\n",
       "    3053,\n",
       "    546,\n",
       "    9552,\n",
       "    22771,\n",
       "    13,\n",
       "    50713],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.34511343638102215,\n",
       "   'compression_ratio': 1.013157894736842,\n",
       "   'no_speech_prob': 0.01058719027787447}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_audio(filename, duration, fs=44100):\n",
    "    if not filename.endswith('.wav'):\n",
    "        filename += '.wav'\n",
    "    print(\"Recording for \", duration, \" seconds.\")\n",
    "    # Record audio\n",
    "    recording = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    print(\"Recording complete. Saving to file.\")\n",
    "    # Save as .wav file\n",
    "    write(filename, fs, recording)  # Save as WAV file \n",
    "    print(\"File saved as: \", os.path.join(os.getcwd(), filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_audio('ignition', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guilhermezago/Documents/GPT-Vectorized-Analysis/.venv/lib/python3.11/site-packages/langchain/llms/openai.py:170: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "/Users/guilhermezago/Documents/GPT-Vectorized-Analysis/.venv/lib/python3.11/site-packages/langchain/llms/openai.py:624: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "zapier = ZapierNLAWrapper()\n",
    "toolkit = ZapierToolkit.from_zapier_nla_wrapper(zapier)\n",
    "agent = initialize_agent(toolkit.get_tools(), llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automated_mail_no_recording():\n",
    "    give_command = small_model.transcribe('ignition.wav')\n",
    "    print(give_command['text'])\n",
    "    answer = agent.run(give_command['text']) \n",
    "    audio2 = generate(\n",
    "        text= answer,\n",
    "        voice=\"Bella\",\n",
    "        model=\"eleven_monolingual_v1\"   \n",
    "    )\n",
    "\n",
    "    play(audio2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio2 = generate(\n",
    "        text= \"this a test to see if it works\",\n",
    "        voice=\"Bella\",\n",
    "        model=\"eleven_monolingual_v1\"   \n",
    "    )\n",
    "play(audio2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guilhermezago/Documents/GPT-Vectorized-Analysis/.venv/lib/python3.11/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Find Gennaro in my contacts list, then send him an email about AI automation.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find Gennaro in the contacts list first.\n",
      "Action: Google Contacts: Find Contact\n",
      "Action Input: Search_By: Gennaro\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m{\"name__first\": \"Gennaro\", \"photo\": \"https://lh3.googleusercontent.com/a-/AD_cMMRK2uBNRVfHfH_PFM90UmQqzREh0AAsQr0bR-82DQ=s100\", \"company\": \"Poatek\", \"emails__undefined\": \"gennaro.rodrigues@gmail.com\", \"originalId\": \"people/c2947311785370170537\", \"update_time\": \"2023-05-22T18:10:46.060251Z\"}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI found Gennaro in the contacts list, now I need to send him an email about AI automation.\n",
      "Action: Gmail: Send Email\n",
      "Action Input: To: gennaro.rodrigues@gmail.com, Subject: AI Automation, Cc: , Body: Hi Gennaro, I wanted to discuss the latest advancements in AI automation and how it can benefit our projects. Let me know when you're available for a chat. Best regards.\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3m{\"labelIds\": \"SENT\"}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: I found Gennaro in the contacts list and sent him an email about AI automation.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "automated_mail_no_recording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automated_mail_test():\n",
    "    record_audio('ignition', 12)\n",
    "    give_command = small_model.transcribe('ignition.wav')\n",
    "    print(give_command['text'])\n",
    "    answer = agent.run(give_command['text']) \n",
    "    audio2 = generate(\n",
    "        text= answer,\n",
    "        voice=\"Bella\",\n",
    "        model=\"eleven_monolingual_v1\"   \n",
    "    )\n",
    "\n",
    "    play(audio2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "automated_mail_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
