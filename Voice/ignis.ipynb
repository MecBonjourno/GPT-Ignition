{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zago\\Documents\\GPT-Vectorized-Analysis\\.venv\\Lib\\site-packages\\whisper\\timing.py:57: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
      "  @numba.jit\n"
     ]
    }
   ],
   "source": [
    "import whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_model = whisper.load_model('small.en')\n",
    "result2 = small_model.transcribe('ignition.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_model = whisper.load_model('large')\n",
    "result = large_model.transcribe('ignition.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' Testing, this is a sound test.',\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 4.0,\n",
       "   'text': ' Testing, this is a sound test.',\n",
       "   'tokens': [50364, 45517, 11, 341, 307, 257, 1626, 1500, 13, 50564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.8204115954312411,\n",
       "   'compression_ratio': 0.8571428571428571,\n",
       "   'no_speech_prob': 0.6790249347686768}],\n",
       " 'language': 'en'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sounddevice\n",
      "  Downloading sounddevice-0.4.6-py3-none-win_amd64.whl (199 kB)\n",
      "                                              0.0/199.7 kB ? eta -:--:--\n",
      "     -----------------------------          153.6/199.7 kB 3.1 MB/s eta 0:00:01\n",
      "     -------------------------------------- 199.7/199.7 kB 3.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy in c:\\users\\zago\\documents\\gpt-vectorized-analysis\\.venv\\lib\\site-packages (1.10.1)\n",
      "Requirement already satisfied: CFFI>=1.0 in c:\\users\\zago\\documents\\gpt-vectorized-analysis\\.venv\\lib\\site-packages (from sounddevice) (1.15.1)\n",
      "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in c:\\users\\zago\\documents\\gpt-vectorized-analysis\\.venv\\lib\\site-packages (from scipy) (1.24.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\zago\\documents\\gpt-vectorized-analysis\\.venv\\lib\\site-packages (from CFFI>=1.0->sounddevice) (2.21)\n",
      "Installing collected packages: sounddevice\n",
      "Successfully installed sounddevice-0.4.6\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sounddevice scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sounddevice as sd\n",
    "from scipy.io.wavfile import write\n",
    "import os\n",
    "\n",
    "def record_audio(filename, duration, fs=44100):\n",
    "    \"\"\"\n",
    "    This function records an audio using microphone and saves it as a .wav file.\n",
    "\n",
    "    Parameters:\n",
    "    filename (str): The name of the .wav file\n",
    "    duration (int): The duration of the recording in seconds\n",
    "    fs (int): The sample rate of the recording. Default is 44100.\n",
    "    \"\"\"\n",
    "    # Check if the filename extension is .wav\n",
    "    if not filename.endswith('.wav'):\n",
    "        filename += '.wav'\n",
    "    \n",
    "    print(\"Recording for \", duration, \" seconds.\")\n",
    "    # Record audio\n",
    "    recording = sd.rec(int(duration * fs), samplerate=fs, channels=1)\n",
    "    sd.wait()  # Wait until recording is finished\n",
    "    print(\"Recording complete. Saving to file.\")\n",
    "    # Save as .wav file\n",
    "    write(filename, fs, recording)  # Save as WAV file \n",
    "    print(\"File saved as: \", os.path.join(os.getcwd(), filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording for  5  seconds.\n",
      "Recording complete. Saving to file.\n",
      "File saved as:  c:\\Users\\Zago\\Documents\\GPT-Vectorized-Analysis\\Voice\\ignition.wav\n"
     ]
    }
   ],
   "source": [
    "# This will record 5 seconds of audio and save it as 'test.wav'\n",
    "record_audio('ignition', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guilhermezago/Documents/GPT-Vectorized-Analysis/.venv/lib/python3.11/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    }
   ],
   "source": [
    "question = model.transcribe('ignition.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ' Fique em general na lista de contatos.',\n",
       " 'segments': [{'id': 0,\n",
       "   'seek': 0,\n",
       "   'start': 0.0,\n",
       "   'end': 4.0,\n",
       "   'text': ' Fique em general na lista de contatos.',\n",
       "   'tokens': [50364,\n",
       "    479,\n",
       "    1925,\n",
       "    846,\n",
       "    2674,\n",
       "    1667,\n",
       "    27764,\n",
       "    368,\n",
       "    660,\n",
       "    26818,\n",
       "    13,\n",
       "    50564],\n",
       "   'temperature': 0.0,\n",
       "   'avg_logprob': -0.9630608191856971,\n",
       "   'compression_ratio': 0.8260869565217391,\n",
       "   'no_speech_prob': 0.03958146274089813}],\n",
       " 'language': 'pt'}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv,find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_gpt3(question, model=\"text-davinci-003\", max_tokens=100):\n",
    "    \"\"\"\n",
    "    This function takes a question string and sends it to GPT-3, which returns a generated response.\n",
    "\n",
    "    Parameters:\n",
    "    question (str): The question to ask GPT-3\n",
    "    model (str): The model to use. Default is \"text-davinci-003\" (as of Sep 2021).\n",
    "    max_tokens (int): The maximum length of the generated response. Default is 100.\n",
    "    \n",
    "    Returns:\n",
    "    str: The generated response from GPT-3.\n",
    "    \"\"\"\n",
    "    response = openai.Completion.create(\n",
    "      engine=model,\n",
    "      prompt=question,\n",
    "      max_tokens=max_tokens\n",
    "    )\n",
    "    \n",
    "    return response.choices[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record_audio('ignition', 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = model.transcribe('ignition.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response=ask_gpt3(question['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is indeed a test.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install elevenlabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from elevenlabs import generate, play\n",
    "\n",
    "from elevenlabs import set_api_key\n",
    "set_api_key('459d05ac3deb06b480705df76f99ac7a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gennaro.rodrigues@gmail.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dotenv extension is already loaded. To reload it, use:\n",
      "  %reload_ext dotenv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "%load_ext dotenv\n",
    "%dotenv\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents.agent_toolkits import ZapierToolkit\n",
    "from langchain.utilities.zapier import ZapierNLAWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zago\\Documents\\GPT-Vectorized-Analysis\\.venv\\Lib\\site-packages\\langchain\\llms\\openai.py:170: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n",
      "c:\\Users\\Zago\\Documents\\GPT-Vectorized-Analysis\\.venv\\Lib\\site-packages\\langchain\\llms\\openai.py:624: UserWarning: You are trying to use a chat model. This way of initializing it is no longer supported. Instead, please use: `from langchain.chat_models import ChatOpenAI`\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "llm = OpenAI(model_name=\"gpt-4\", temperature=0)\n",
    "zapier = ZapierNLAWrapper()\n",
    "toolkit = ZapierToolkit.from_zapier_nla_wrapper(zapier)\n",
    "agent = initialize_agent(toolkit.get_tools(), llm, agent=\"zero-shot-react-description\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automated_mail_test():\n",
    "    record_audio('ignition', 13)\n",
    "    give_command = medium_model.transcribe('ignition.wav')\n",
    "    print(give_command['text'])\n",
    "    # audio = generate(\n",
    "    #     text=\"I will send an email to Gennaro about it\",\n",
    "    #     voice=\"Bella\",\n",
    "    #     model=\"eleven_monolingual_v1\"   \n",
    "    # )\n",
    "\n",
    "    # play(audio)\n",
    "    answer = agent.run(give_command['text']) \n",
    "    audio2 = generate(\n",
    "        text= answer,\n",
    "        voice=\"Bella\",\n",
    "        model=\"eleven_monolingual_v1\"   \n",
    "    )\n",
    "\n",
    "    play(audio2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_task():\n",
    "    # record_audio('ignition', 11)\n",
    "    give_command = medium_model.transcribe('ignition.wav')\n",
    "    print(give_command['text'])\n",
    "    answer = agent.run(give_command['text']) \n",
    "    print(answer)\n",
    "    audio = generate(\n",
    "        text=answer,\n",
    "        voice=\"Bella\",\n",
    "        model=\"eleven_monolingual_v1\"   \n",
    "    )\n",
    "\n",
    "    play(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_task()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording for  13  seconds.\n",
      "Recording complete. Saving to file.\n",
      "File saved as:  c:\\Users\\Zago\\Documents\\GPT-Vectorized-Analysis\\Voice\\ignition.wav\n",
      " Find Gennaro in my contacts list, then write a paragraph about how Penny's size doesn't matter in life and send him in the email.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find Gennaro in the contacts list first.\n",
      "Action: Google Contacts: Find Contact\n",
      "Action Input: {'Search_By': 'Gennaro'}\u001b[0m\n",
      "Observation: \u001b[31;1m\u001b[1;3m{\"name__first\": \"Gennaro\", \"photo\": \"https://lh3.googleusercontent.com/a-/ACB-R5R4K-hGFwZBjqHdiVAUA01p_JUSngaStgb0GUP4Ag=s100\", \"emails__undefined\": \"gennaro.rodrigues@gmail.com\", \"company\": \"Poatek\", \"update_time\": \"2023-05-22T18:10:46.060251Z\", \"originalId\": \"people/c2947311785370170537\"}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI found Gennaro in the contacts list. Now I need to write a paragraph about how Penny's size doesn't matter in life and send it to him in an email.\n",
      "Action: Gmail: Send Email\n",
      "Action Input: {'To': 'gennaro.rodrigues@gmail.com', 'Subject': \"Penny's Size Doesn't Matter\", 'Body': \"Hi Gennaro,\\n\\nI wanted to share some thoughts about Penny. Despite her small size, it's important to remember that size doesn't define a person's worth or capabilities. Penny has proven time and time again that she is strong, intelligent, and capable of achieving great things. Her determination and resilience are what truly matter in life, not her physical size. Let's continue to support and encourage Penny to reach her full potential, regardless of her size.\\n\\nBest regards,\\n[Your Name]\", 'Cc': ''}\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{\"labelIds\": \"SENT\"}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: I found Gennaro in the contacts list and sent him an email with a paragraph about how Penny's size doesn't matter in life.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "automated_mail_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def automated_mail_test_no_recording():\n",
    "    record_audio('ignition', 10)\n",
    "    give_command = medium_model.transcribe('ignition.wav')\n",
    "    print(give_command['text'])\n",
    "    # audio = generate(\n",
    "    #     text=\"I will send an email to Gennaro Rodrigues about it\",\n",
    "    #     voice=\"Bella\",\n",
    "    #     model=\"eleven_monolingual_v1\"   \n",
    "    # )\n",
    "\n",
    "    # play(audio)\n",
    "    answer = agent.run(give_command['text']) \n",
    "    audio2 = generate(\n",
    "        text=,\n",
    "        voice=\"Bella\",\n",
    "        model=\"eleven_monolingual_v1\"   \n",
    "    )\n",
    "\n",
    "    play(audio2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/guilhermezago/Documents/GPT-Vectorized-Analysis/.venv/lib/python3.11/site-packages/whisper/transcribe.py:114: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Find Vico in my contacts and send him an email about grocery shopping online.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to find Vico's contact information first.\n",
      "Action: Google Contacts: Find Contact\n",
      "Action Input: Search_By: Vico\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{\"name__first\": \"Vico\", \"photo\": \"https://lh3.googleusercontent.com/cm/AOLgnvvUuFmoJ_w4iia61N4tc8iDiaqjGZP54HmGlqE3O8Bv40dXBzodL61G-XxwjQQe=s100\", \"company\": \"Sooply\", \"emails__undefined\": \"vicogrippa@gmail.com\", \"originalId\": \"people/c1619328672299322477\", \"update_time\": \"2023-05-22T18:32:13.343606Z\"}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI found Vico's contact information, now I need to send him an email about grocery shopping online.\n",
      "Action: Gmail: Send Email\n",
      "Action Input: To: vicogrippa@gmail.com, Body: Hi Vico, I wanted to discuss grocery shopping online. Let me know your thoughts and any recommendations you have. Thanks!, Cc: , Subject: Grocery Shopping Online\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m{\"threadId\": \"18844bdba0a2d930\", \"labelIds\": \"SENT\"}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: I found Vico in your contacts and sent him an email about grocery shopping online.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "automated_mail_test_no_recording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
